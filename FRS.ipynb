{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-dd5bbc7bc9a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## pip install opencv-python\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "## pip install opencv-python\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:9: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:9: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-4-17bc371e8cf2>:9: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    }
   ],
   "source": [
    "def generate_dataset():\n",
    "    face_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "    def face_cropped(img):\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "        # scaling factor = 1.3\n",
    "        # minimum neighbor = 5\n",
    "        \n",
    "        if faces is ():\n",
    "            return None\n",
    "        for (x,y,w,h) in faces:\n",
    "            cropped_face = img[y:y+h,x:x+w]\n",
    "        return cropped_face\n",
    "    \n",
    "    cap = cv2.VideoCapture(1)\n",
    "    id =3\n",
    "    img_id = 0\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if face_cropped(frame) is not None:\n",
    "            img_id+=1\n",
    "            face = cv2.resize(face_cropped(frame), (200,200))\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "            file_name_path = \"data/user.\"+str(id)+\".\"+str(img_id)+\".jpg\"\n",
    "            cv2.imwrite(file_name_path, face)\n",
    "            cv2.putText(face, str(img_id), (50,50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            \n",
    "            cv2.imshow(\"Cropped face\", face)\n",
    "            \n",
    "        if cv2.waitKey(1)==13 or int(img_id)==200: #13 is the ASCII character of Enter\n",
    "            break\n",
    "            \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Collecting samples is completed....\")\n",
    "#generate_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the classifier and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-dd61b6b368bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;31m#pip install pillow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m    \u001b[0;31m# pip install numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image #pip install pillow\n",
    "import numpy as np    # pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-dd67ecd9455b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfaces\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"classifier.xml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mtrain_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-dd67ecd9455b>\u001b[0m in \u001b[0;36mtrain_classifier\u001b[0;34m(data_dir)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data'"
     ]
    }
   ],
   "source": [
    "def train_classifier(data_dir):\n",
    "    path = [os.path.join(data_dir, f) for f in os.listdir(data_dir)]\n",
    "    \n",
    "    faces = []\n",
    "    ids = []\n",
    "    \n",
    "    for image in path:\n",
    "        img = Image.open(image).convert('L')\n",
    "        imageNp = np.array(img, 'uint8')\n",
    "        id = int(os.path.split(image)[1].split(\".\")[1])\n",
    "        \n",
    "        faces.append(imageNp)\n",
    "        ids.append(id)\n",
    "        \n",
    "    ids = np.array(ids)\n",
    "    \n",
    "    # Train and save classifier\n",
    "    clf = cv2.face.LBPHFaceRecognizer_create()\n",
    "    clf.train(faces,ids)\n",
    "    clf.write(\"classifier.xml\")\n",
    "train_classifier(\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect the faces and give the name if it is already stored in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-636574818d39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f5d38133760a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# loading classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mfaceCascade\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCascadeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"haarcascade_frontalface_default.xml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLBPHFaceRecognizer_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "def draw_boundary(img, classifier, scaleFactor, minNeighbors, color, text, clf):\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    features = classifier.detectMultiScale(gray_img, scaleFactor, minNeighbors)\n",
    "    \n",
    "    for (x,y,w,h) in features:\n",
    "        cv2.rectangle(img, (x,y), (x+w,y+h), color, 2 )\n",
    "        \n",
    "        id, pred = clf.predict(gray_img[y:y+h,x:x+w])\n",
    "        confidence = int(100*(1-pred/300))\n",
    "        \n",
    "        if confidence>70:\n",
    "            if id==1:\n",
    "                cv2.putText(img, \"Ishwar\", (x,y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 1, cv2.LINE_AA)\n",
    "            if id==2:\n",
    "                cv2.putText(img, \"Manish\", (x,y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 1, cv2.LINE_AA)\n",
    "        else:\n",
    "            cv2.putText(img, \"UNKNOWN\", (x,y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,0,255), 1, cv2.LINE_AA)\n",
    "    \n",
    "    return img\n",
    "\n",
    "# loading classifier\n",
    "faceCascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "clf = cv2.face.LBPHFaceRecognizer_create()\n",
    "clf.read(\"classifier.xml\")\n",
    "\n",
    "video_capture = cv2.VideoCapture(1)\n",
    "\n",
    "while True:\n",
    "    ret, img = video_capture.read()\n",
    "    img = draw_boundary(img, faceCascade, 1.3, 6, (255,255,255), \"Face\", clf)\n",
    "    cv2.imshow(\"face Detection\", img)\n",
    "    \n",
    "    if cv2.waitKey(1)==13:\n",
    "        break\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GUI face recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "libtk8.6.so: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3d3af53977b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtkinter\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtkinter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmessagebox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/tkinter/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0m_tkinter\u001b[0m \u001b[0;31m# If this fails your Python may not be configured for Tk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mTclError\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tkinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTclError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtkinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstants\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: libtk8.6.so: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0468734cc838>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwindow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Face Recognition system\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0ml1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfont\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Algerian\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0ml1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tk' is not defined"
     ]
    }
   ],
   "source": [
    "window = tk.Tk()\n",
    "window.title(\"Face Recognition system\")\n",
    "\n",
    "l1 = tk.Label(window, text=\"Name\", font=(\"Algerian\",20))\n",
    "l1.grid(column=0, row=0)\n",
    "t1 = tk.Entry(window, width=50, bd=5)\n",
    "t1.grid(column=1, row=0)\n",
    "\n",
    "l2 = tk.Label(window, text=\"Age\", font=(\"Algerian\",20))\n",
    "l2.grid(column=0, row=1)\n",
    "t2 = tk.Entry(window, width=50, bd=5)\n",
    "t2.grid(column=1, row=1)\n",
    "\n",
    "l3 = tk.Label(window, text=\"Address\", font=(\"Algerian\",20))\n",
    "l3.grid(column=0, row=2)\n",
    "t3 = tk.Entry(window, width=50, bd=5)\n",
    "t3.grid(column=1, row=2)\n",
    "\n",
    "\n",
    "b1 = tk.Button(window, text=\"Training\", font=(\"Algerian\",20),bg=\"orange\",fg=\"red\")\n",
    "b1.grid(column=0, row=4)\n",
    "\n",
    "b2 = tk.Button(window, text=\"Detect the faces\", font=(\"Algerian\",20), bg=\"green\", fg=\"orange\")\n",
    "b2.grid(column=1, row=4)\n",
    "\n",
    "b3 = tk.Button(window, text=\"Generate dataset\", font=(\"Algerian\",20), bg=\"pink\", fg=\"black\")\n",
    "b3.grid(column=2, row=4)\n",
    "\n",
    "window.geometry(\"800x200\")\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-0e9f4e6f2b38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmysql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnector\u001b[0m  \u001b[0;31m# pip install mysql-connector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import mysql.connector  # pip install mysql-connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:129: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:129: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8850ed090e23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwindow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Face Recognition system\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresizable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0ml1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfont\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Algerian\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tk' is not defined"
     ]
    }
   ],
   "source": [
    "window = tk.Tk()\n",
    "window.title(\"Face Recognition system\")\n",
    "window.resizable(0,0)\n",
    "\n",
    "l1 = tk.Label(window, text=\"Name\", font=(\"Algerian\",20))\n",
    "l1.grid(column=0, row=0)\n",
    "t1 = tk.Entry(window, width=50, bd=5)\n",
    "t1.grid(column=1, row=0)\n",
    "\n",
    "l2 = tk.Label(window, text=\"Age\", font=(\"Algerian\",20))\n",
    "l2.grid(column=0, row=1)\n",
    "t2 = tk.Entry(window, width=50, bd=5)\n",
    "t2.grid(column=1, row=1)\n",
    "\n",
    "l3 = tk.Label(window, text=\"Address\", font=(\"Algerian\",20))\n",
    "l3.grid(column=0, row=2)\n",
    "t3 = tk.Entry(window, width=50, bd=5)\n",
    "t3.grid(column=1, row=2)\n",
    "\n",
    "def train_classifier():\n",
    "    data_dir = \"C:/Users/Ishwar Gautam/Desktop/Face Recognition System/data\"\n",
    "    path = [os.path.join(data_dir, f) for f in os.listdir(data_dir)]\n",
    "    \n",
    "    faces = []\n",
    "    ids = []\n",
    "    \n",
    "    for image in path:\n",
    "        img = Image.open(image).convert('L')\n",
    "        imageNp = np.array(img, 'uint8')\n",
    "        id = int(os.path.split(image)[1].split(\".\")[1])\n",
    "        \n",
    "        faces.append(imageNp)\n",
    "        ids.append(id)\n",
    "        \n",
    "    ids = np.array(ids)\n",
    "    \n",
    "    # Train and save classifier\n",
    "    clf = cv2.face.LBPHFaceRecognizer_create()\n",
    "    clf.train(faces,ids)\n",
    "    clf.write(\"classifier.xml\")\n",
    "    messagebox.showinfo(\"Result\",\"Model trained completed.....\")\n",
    "    \n",
    "b1 = tk.Button(window, text=\"Training\", font=(\"Algerian\",20),bg=\"orange\",fg=\"red\", command=train_classifier)\n",
    "b1.grid(column=0, row=4)\n",
    "\n",
    "def detect_face():\n",
    "    \n",
    "    def draw_boundary(img, classifier, scaleFactor, minNeighbors, color, text, clf):\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        features = classifier.detectMultiScale(gray_img, scaleFactor, minNeighbors)\n",
    "\n",
    "        for (x,y,w,h) in features:\n",
    "            cv2.rectangle(img, (x,y), (x+w,y+h), color, 2 )\n",
    "\n",
    "            id, pred = clf.predict(gray_img[y:y+h,x:x+w])\n",
    "            confidence = int(100*(1-pred/300))\n",
    "            \n",
    "            mydb = mysql.connector.connect(\n",
    "            host = \"localhost\",\n",
    "            user = \"root\",\n",
    "            passwd = \"\",\n",
    "            database = \"Authorized_user\"\n",
    "            )\n",
    "            mycursor = mydb.cursor()\n",
    "            \n",
    "            mycursor.execute(\"select name from my_table where id=\" + str(id))\n",
    "            s = mycursor.fetchone() #tuple\n",
    "            \n",
    "            s  = ''+''.join(s) #string\n",
    "            \n",
    "            if confidence>70:\n",
    "                cv2.putText(img, s , (x,y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 1, cv2.LINE_AA)\n",
    "            else:\n",
    "                cv2.putText(img, \"UNKNOWN\", (x,y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,0,255), 1, cv2.LINE_AA)\n",
    "\n",
    "        return img\n",
    "\n",
    "    # loading classifier\n",
    "    faceCascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "    clf = cv2.face.LBPHFaceRecognizer_create()\n",
    "    clf.read(\"classifier.xml\")\n",
    "\n",
    "    video_capture = cv2.VideoCapture(1)\n",
    "\n",
    "    while True:\n",
    "        ret, img = video_capture.read()\n",
    "        img = draw_boundary(img, faceCascade, 1.3, 6, (255,255,255), \"Face\", clf)\n",
    "        cv2.imshow(\"face Detection\", img)\n",
    "\n",
    "        if cv2.waitKey(1)==13:\n",
    "            break\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "b2 = tk.Button(window, text=\"Detect the faces\", font=(\"Algerian\",20), bg=\"green\", fg=\"orange\", command=detect_face)\n",
    "b2.grid(column=1, row=4)\n",
    "\n",
    "def generate_dataset():\n",
    "    if (t1.get()==\"\" or t2.get()==\"\" or t3.get()==\"\"):\n",
    "        messagebox.showinfo(\"Result\",\"Please provide complete details of the user...\")\n",
    "    else:\n",
    "        mydb = mysql.connector.connect(\n",
    "            host = \"localhost\",\n",
    "            user = \"root\",\n",
    "            passwd = \"\",\n",
    "            database = \"Authorized_user\"\n",
    "        )\n",
    "        mycursor = mydb.cursor()\n",
    "        mycursor.execute(\"SELECT * from my_table\")\n",
    "        myresult = mycursor.fetchall()\n",
    "        \n",
    "        id = 1\n",
    "        for x in myresult:\n",
    "            id +=1\n",
    "        \n",
    "        sql = \"insert into my_table(id,name,age,address) values(%s, %s, %s, %s)\"\n",
    "        val = (id, t1.get(), t2.get(), t3.get())\n",
    "        mycursor.execute(sql,val)\n",
    "        mydb.commit()\n",
    "        \n",
    "        face_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "        def face_cropped(img):\n",
    "            gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "            faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "            # scaling factor = 1.3\n",
    "            # minimum neighbor = 5\n",
    "\n",
    "            if faces is ():\n",
    "                return None\n",
    "            for (x,y,w,h) in faces:\n",
    "                cropped_face = img[y:y+h,x:x+w]\n",
    "            return cropped_face\n",
    "\n",
    "        cap = cv2.VideoCapture(1)\n",
    "        img_id = 0\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if face_cropped(frame) is not None:\n",
    "                img_id+=1\n",
    "                face = cv2.resize(face_cropped(frame), (200,200))\n",
    "                face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "                file_name_path = \"data/user.\"+str(id)+\".\"+str(img_id)+\".jpg\"\n",
    "                cv2.imwrite(file_name_path, face)\n",
    "                cv2.putText(face, str(img_id), (50,50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "\n",
    "                cv2.imshow(\"Cropped face\", face)\n",
    "\n",
    "            if cv2.waitKey(1)==13 or int(img_id)==200: #13 is the ASCII character of Enter\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        messagebox.showinfo(\"Result\",\"Generating dataset is completed.....\")\n",
    "\n",
    "b3 = tk.Button(window, text=\"Generate dataset\", font=(\"Algerian\",20), bg=\"pink\", fg=\"black\", command=generate_dataset)\n",
    "b3.grid(column=2, row=4)\n",
    "\n",
    "window.geometry(\"800x200\")\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final GUI Face Recognition system using Tkinter canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "libtk8.6.so: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-b3e792e5e23b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtkinter\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtkinter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageTk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/tkinter/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0m_tkinter\u001b[0m \u001b[0;31m# If this fails your Python may not be configured for Tk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mTclError\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tkinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTclError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtkinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstants\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: libtk8.6.so: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import *\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image, ImageTk\n",
    "import numpy as np\n",
    "import mysql.connector\n",
    "from tkinter import messagebox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Divide window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-bf3b31a151bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwindow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Project\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresizable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mload1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"header.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tk' is not defined"
     ]
    }
   ],
   "source": [
    "window = tk.Tk()\n",
    "window.title(\"Project\")\n",
    "window.resizable(0,0)\n",
    "\n",
    "load1 = Image.open(\"header.png\")\n",
    "photo1 = ImageTk.PhotoImage(load1)\n",
    "\n",
    "\n",
    "header = tk.Button(window, image=photo1)\n",
    "header.place(x=5, y=0)\n",
    "\n",
    "canvas1 = Canvas(window, width = 500, height=250, bg='ivory')\n",
    "canvas1.place(x=5, y=120)\n",
    "\n",
    "l1 = tk.Button(canvas1, text=\"Name\", font=(\"Algerian\",15))\n",
    "l1.place(x=5, y=5)\n",
    "t1 = tk.Entry(canvas1, width=50, bd=5)\n",
    "t1.place(x=150, y=10)\n",
    "\n",
    "l2 = tk.Button(canvas1, text=\"Age\", font=(\"Algerian\",15))\n",
    "l2.place(x=5, y=50)\n",
    "t2 = tk.Entry(canvas1, width=50, bd=5)\n",
    "t2.place(x=150, y=55)\n",
    "\n",
    "l3 = tk.Button(canvas1, text=\"Address\", font=(\"Algerian\",15))\n",
    "l3.place(x=5, y=100)\n",
    "t3 = tk.Entry(canvas1, width=50, bd=5)\n",
    "t3.place(x=150, y=105)\n",
    "\n",
    "\n",
    "b1= tk.Button(canvas1, text=\"Training\", font=(\"Algerian\",20), bg='orange', fg='red')\n",
    "b1.place(x=10, y=180)\n",
    "\n",
    "b2= tk.Button(canvas1, text=\"Generate dataset\", font=(\"Algerian\",20), bg='pink', fg='black')\n",
    "b2.place(x=175, y=180)\n",
    "\n",
    "load2= Image.open(\"canvas2.png\")\n",
    "photo2 = ImageTk.PhotoImage(load2)\n",
    "\n",
    "canvas2 =  Canvas(window, width=500, height=250)\n",
    "canvas2.place(x=5, y=400)\n",
    "canvas2.create_image(250,125,image=photo2)\n",
    "\n",
    "b3 = tk.Button(canvas2, text=\"Capture the image\", font=(\"Algerian\",20), bg=\"gray\", fg=\"black\")\n",
    "b3.place(x=5, y=50)\n",
    "\n",
    "b4 = tk.Button(canvas2, text=\"Predict face from live video\", font=(\"Algerian\", 20), bg=\"cyan\", fg=\"black\")\n",
    "b4.place(x=5, y=150)\n",
    "\n",
    "load3= Image.open('canvas3.png')\n",
    "photo3 = ImageTk.PhotoImage(load3)\n",
    "\n",
    "canvas3 = Canvas(window, width=280, height=530)\n",
    "canvas3.place(x=515, y=120)\n",
    "canvas3.create_image(140, 265, image=photo3)\n",
    "\n",
    "window.geometry(\"800x680\")\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here is the final code....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:88: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:145: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:88: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:145: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-c4021c4341cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwindow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Project\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresizable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mload1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"header.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tk' is not defined"
     ]
    }
   ],
   "source": [
    "window = tk.Tk()\n",
    "window.title(\"Project\")\n",
    "window.resizable(0,0)\n",
    "\n",
    "load1 = Image.open(\"header.png\")\n",
    "photo1 = ImageTk.PhotoImage(load1)\n",
    "\n",
    "\n",
    "header = tk.Button(window, image=photo1)\n",
    "header.place(x=5, y=0)\n",
    "\n",
    "canvas1 = Canvas(window, width = 500, height=250, bg='ivory')\n",
    "canvas1.place(x=5, y=120)\n",
    "\n",
    "l1 = tk.Button(canvas1, text=\"Name\", font=(\"Algerian\",15))\n",
    "l1.place(x=5, y=5)\n",
    "t1 = tk.Entry(canvas1, width=50, bd=5)\n",
    "t1.place(x=150, y=10)\n",
    "\n",
    "l2 = tk.Button(canvas1, text=\"Age\", font=(\"Algerian\",15))\n",
    "l2.place(x=5, y=50)\n",
    "t2 = tk.Entry(canvas1, width=50, bd=5)\n",
    "t2.place(x=150, y=55)\n",
    "\n",
    "l3 = tk.Button(canvas1, text=\"Address\", font=(\"Algerian\",15))\n",
    "l3.place(x=5, y=100)\n",
    "t3 = tk.Entry(canvas1, width=50, bd=5)\n",
    "t3.place(x=150, y=105)\n",
    "\n",
    "def train_classifier():\n",
    "    data_dir = \"C:/Users/Ishwar Gautam/Desktop/Face Recognition System/data\"\n",
    "    path = [os.path.join(data_dir, f) for f in os.listdir(data_dir)]\n",
    "    \n",
    "    faces = []\n",
    "    ids = []\n",
    "    \n",
    "    for image in path:\n",
    "        img = Image.open(image).convert('L')\n",
    "        imageNp = np.array(img, 'uint8')\n",
    "        id = int(os.path.split(image)[1].split(\".\")[1])\n",
    "        \n",
    "        faces.append(imageNp)\n",
    "        ids.append(id)\n",
    "        \n",
    "    ids = np.array(ids)\n",
    "    \n",
    "    # Train and save classifier\n",
    "    clf = cv2.face.LBPHFaceRecognizer_create()\n",
    "    clf.train(faces,ids)\n",
    "    clf.write(\"classifier.xml\")\n",
    "    messagebox.showinfo(\"Result\",\"Model trained completed.....\")\n",
    "    \n",
    "\n",
    "b1= tk.Button(canvas1, text=\"Training\", font=(\"Algerian\",20), bg='orange', fg='red', command=train_classifier)\n",
    "b1.place(x=10, y=180)\n",
    "\n",
    "\n",
    "def generate_dataset():\n",
    "    if (t1.get()==\"\" or t2.get()==\"\" or t3.get()==\"\"):\n",
    "        messagebox.showinfo(\"Result\",\"Please provide complete details of the user...\")\n",
    "    else:\n",
    "        mydb = mysql.connector.connect(\n",
    "            host = \"localhost\",\n",
    "            user = \"root\",\n",
    "            passwd = \"\",\n",
    "            database = \"Authorized_user\"\n",
    "        )\n",
    "        mycursor = mydb.cursor()\n",
    "        mycursor.execute(\"SELECT * from my_table\")\n",
    "        myresult = mycursor.fetchall()\n",
    "        \n",
    "        id = 1\n",
    "        for x in myresult:\n",
    "            id +=1\n",
    "        \n",
    "        sql = \"insert into my_table(id,name,age,address) values(%s, %s, %s, %s)\"\n",
    "        val = (id, t1.get(), t2.get(), t3.get())\n",
    "        mycursor.execute(sql,val)\n",
    "        mydb.commit()\n",
    "        \n",
    "        face_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "        def face_cropped(img):\n",
    "            gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "            faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "            # scaling factor = 1.3\n",
    "            # minimum neighbor = 5\n",
    "\n",
    "            if faces is ():\n",
    "                return None\n",
    "            for (x,y,w,h) in faces:\n",
    "                cropped_face = img[y:y+h,x:x+w]\n",
    "            return cropped_face\n",
    "\n",
    "        cap = cv2.VideoCapture(1)\n",
    "        img_id = 0\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if face_cropped(frame) is not None:\n",
    "                img_id+=1\n",
    "                face = cv2.resize(face_cropped(frame), (200,200))\n",
    "                face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "                file_name_path = \"data/user.\"+str(id)+\".\"+str(img_id)+\".jpg\"\n",
    "                cv2.imwrite(file_name_path, face)\n",
    "                cv2.putText(face, str(img_id), (50,50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "\n",
    "                cv2.imshow(\"Cropped face\", face)\n",
    "\n",
    "            if cv2.waitKey(1)==13 or int(img_id)==200: #13 is the ASCII character of Enter\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        messagebox.showinfo(\"Result\",\"Generating dataset is completed.....\")\n",
    "\n",
    "b2= tk.Button(canvas1, text=\"Generate dataset\", font=(\"Algerian\",20), bg='pink', fg='black', command = generate_dataset)\n",
    "b2.place(x=175, y=180)\n",
    "\n",
    "load2= Image.open(\"canvas2.png\")\n",
    "photo2 = ImageTk.PhotoImage(load2)\n",
    "\n",
    "canvas2 =  Canvas(window, width=500, height=250)\n",
    "canvas2.place(x=5, y=400)\n",
    "canvas2.create_image(250,125,image=photo2)\n",
    "\n",
    "\n",
    "def capture_image():\n",
    "    \n",
    "    canvas3 = Canvas(window, width=280, height=530)\n",
    "    canvas3.place(x=515, y=120)\n",
    "    canvas3.create_image(140, 265, image=photo3)\n",
    "    \n",
    "    cap = cv2.VideoCapture(1)\n",
    "    if cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "    else:\n",
    "        ret = False\n",
    "    \n",
    "    face_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    # scaling factor = 1.3\n",
    "    # minimum neighbor = 5\n",
    "\n",
    "    if faces is ():\n",
    "        print(\"No face detected..\")\n",
    "        return None\n",
    "    else:\n",
    "        for (x,y,w,h) in faces:\n",
    "            cropped_face = frame[y:y+h,x:x+w]\n",
    "        cv2.imwrite(\"captured_image.jpg\", cropped_face)\n",
    "\n",
    "        load = Image.open(\"captured_image.jpg\")\n",
    "        photo = ImageTk.PhotoImage(load)\n",
    "\n",
    "        # Labels can be text or images\n",
    "        img = Label(canvas3, image=photo, width=200, height=200)\n",
    "        img.image = photo\n",
    "\n",
    "        img.place(x=0, y=5)\n",
    "\n",
    "        cap.release()\n",
    "    \n",
    "    clf = cv2.face.LBPHFaceRecognizer_create()\n",
    "    clf.read(\"classifier.xml\")\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        id, pred = clf.predict(gray[y:y+h,x:x+w])\n",
    "        #confidence = int(100*(1-pred/300))\n",
    "\n",
    "        mydb = mysql.connector.connect(\n",
    "        host = \"localhost\",\n",
    "        user = \"root\",\n",
    "        passwd = \"\",\n",
    "        database = \"Authorized_user\"\n",
    "        )\n",
    "        mycursor = mydb.cursor()\n",
    "\n",
    "        mycursor.execute(\"select name,age,address from my_table where id=\" + str(id))\n",
    "        s = mycursor.fetchall()\n",
    "        \n",
    "        a1 = tk.Label(canvas3, text=\"Name = \", font=(\"Algerian\",20))\n",
    "        a1.place(x=5, y=250)\n",
    "        \n",
    "        b1 = tk.Label(canvas3, text=s[0][0], font=(\"Algerian\",20))\n",
    "        b1.place(x=100, y=250)\n",
    "        \n",
    "        c1 = tk.Label(canvas3, text=\"Age = \", font=(\"Algerian\",20))\n",
    "        c1.place(x=5, y=300)\n",
    "        \n",
    "        d1 = tk.Label(canvas3, text = s[0][1], font=(\"Algerian\", 20))\n",
    "        d1.place(x=100, y=300)\n",
    "        \n",
    "        e1 = tk.Label(canvas3, text=\"Address = \", font=(\"Algerian\", 20))\n",
    "        e1.place(x=5, y=350)\n",
    "        \n",
    "        f1 = tk.Label(canvas3, text= s[0][2], font=(\"Algerian\",20))\n",
    "        f1.place(x=150, y=350)\n",
    "    \n",
    "    \n",
    "b3 = tk.Button(canvas2, text=\"Capture the image\", font=(\"Algerian\",20), bg=\"gray\", fg=\"black\", command=capture_image)\n",
    "b3.place(x=5, y=50)\n",
    "\n",
    "def detect_face():\n",
    "    \n",
    "    def draw_boundary(img, classifier, scaleFactor, minNeighbors, color, text, clf):\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        features = classifier.detectMultiScale(gray_img, scaleFactor, minNeighbors)\n",
    "\n",
    "        for (x,y,w,h) in features:\n",
    "            cv2.rectangle(img, (x,y), (x+w,y+h), color, 2 )\n",
    "\n",
    "            id, pred = clf.predict(gray_img[y:y+h,x:x+w])\n",
    "            confidence = int(100*(1-pred/300))\n",
    "            \n",
    "            mydb = mysql.connector.connect(\n",
    "            host = \"localhost\",\n",
    "            user = \"root\",\n",
    "            passwd = \"\",\n",
    "            database = \"Authorized_user\"\n",
    "            )\n",
    "            mycursor = mydb.cursor()\n",
    "            \n",
    "            mycursor.execute(\"select name from my_table where id=\" + str(id))\n",
    "            s = mycursor.fetchone() #tuple\n",
    "            \n",
    "            s  = ''+''.join(s) #string\n",
    "            \n",
    "            if confidence>70:\n",
    "                cv2.putText(img, s , (x,y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 1, cv2.LINE_AA)\n",
    "            else:\n",
    "                cv2.putText(img, \"UNKNOWN\", (x,y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,0,255), 1, cv2.LINE_AA)\n",
    "\n",
    "        return img\n",
    "\n",
    "    # loading classifier\n",
    "    faceCascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "    clf = cv2.face.LBPHFaceRecognizer_create()\n",
    "    clf.read(\"classifier.xml\")\n",
    "\n",
    "    video_capture = cv2.VideoCapture(1)\n",
    "\n",
    "    while True:\n",
    "        ret, img = video_capture.read()\n",
    "        img = draw_boundary(img, faceCascade, 1.3, 6, (255,255,255), \"Face\", clf)\n",
    "        cv2.imshow(\"face Detection\", img)\n",
    "\n",
    "        if cv2.waitKey(1)==13:\n",
    "            break\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "b4 = tk.Button(canvas2, text=\"Predict face from live video\", font=(\"Algerian\", 20), bg=\"cyan\", fg=\"black\", command=detect_face)\n",
    "b4.place(x=5, y=150)\n",
    "\n",
    "load3= Image.open('canvas3.png')\n",
    "photo3 = ImageTk.PhotoImage(load3)\n",
    "\n",
    "canvas3 = Canvas(window, width=280, height=530)\n",
    "canvas3.place(x=515, y=120)\n",
    "canvas3.create_image(140, 265, image=photo3)\n",
    "\n",
    "window.geometry(\"800x680\")\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[1,221,1,23,2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 2, 23, 221]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
